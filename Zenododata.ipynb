{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqp7l2P7pwIi",
        "outputId": "b8f118a0-8992-4bed-a20c-a7f92bcc5154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 2163.69 MB\n",
            "Download complete!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "# URL of the tar.gz file\n",
        "url = \"https://zenodo.org/record/8386668/files/circular_fashion_v1.tar.gz\"\n",
        "local_filename = \"circular_fashion_v1.tar.gz\"\n",
        "\n",
        "def download_file(url, local_filename):\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        total_size = int(r.headers.get('content-length', 0))\n",
        "        with open(local_filename, 'wb') as f:\n",
        "            downloaded = 0\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    downloaded += len(chunk)\n",
        "                    done = int(50 * downloaded / total_size)\n",
        "                    print(f'\\r[{\"=\" * done}{\" \" * (50 - done)}] {downloaded / (1024 * 1024):.2f} MB', end='')\n",
        "    print(\"\\nDownload complete!\")\n",
        "\n",
        "def extract_tar_gz(file_name):\n",
        "    with tarfile.open(file_name, \"r:gz\") as tar:\n",
        "        tar.extractall()\n",
        "    print(\"Extraction complete!\")\n",
        "\n",
        "# Download the file\n",
        "download_file(url, local_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the tar.gz file\n",
        "extract_tar_gz(local_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5oGDPwRq2DO",
        "outputId": "b0652b1f-407d-475b-8324-b7c4a5542934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List the contents of the extracted folder\n",
        "extracted_files = os.listdir()\n",
        "print(\"Extracted files:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF-F6Mcdqmws",
        "outputId": "be932b03-7f73-4590-9890-2874041844d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['.config', 'README.md', 'nov2022', 'dataset.tar.gz', 'LICENSE', 'circular_fashion_v1.tar.gz', 'feb2023', 'jan2023', 'sep2022', 'oct2022', 'dec2022', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "read_json_file(\"/content/jan2023/2023-01-31/labels_2023_01_31_11_34_01.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y26vbHKD0wWz",
        "outputId": "d46e5d88-5d01-49c1-f2ac-66032cf6479a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/jan2023/2023-01-31/labels_2023_01_31_11_34_01.json:\n",
            " {\n",
            "    \"brand\": \"Puma\",\n",
            "    \"brandtext\": \"\",\n",
            "    \"category\": \"Men\",\n",
            "    \"type\": \"Trousers\",\n",
            "    \"size\": \"M \",\n",
            "    \"colors\": [\n",
            "        \"Black\"\n",
            "    ],\n",
            "    \"season\": \"None\",\n",
            "    \"pilling\": 5,\n",
            "    \"condition\": 3,\n",
            "    \"price\": \"50-100\",\n",
            "    \"annotator\": \"13\",\n",
            "    \"cut\": [],\n",
            "    \"pattern\": \"None\",\n",
            "    \"trend\": \"None\",\n",
            "    \"smell\": \"None\",\n",
            "    \"stains\": \"None\",\n",
            "    \"holes\": \"None\",\n",
            "    \"damage\": \"Holes in seams\",\n",
            "    \"material\": \"100% polyester\",\n",
            "    \"comment\": \"\",\n",
            "    \"usage\": \"Export\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def list_all_json_files(directory):\n",
        "    json_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.json'):\n",
        "                json_files.append(os.path.join(root, filename))\n",
        "    return json_files\n",
        "\n",
        "def read_and_concatenate_json_files(json_files):\n",
        "    data_frames = []\n",
        "    for json_file_path in json_files:\n",
        "        try:\n",
        "            with open(json_file_path, 'r') as file:\n",
        "                data = json.load(file)\n",
        "\n",
        "\n",
        "                if isinstance(data, list):\n",
        "                    df = pd.json_normalize(data)\n",
        "                else:\n",
        "                    df = pd.json_normalize([data])\n",
        "\n",
        "                data_frames.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Gagal membaca {json_file_path}: {e}\")\n",
        "\n",
        "    # Concatenate all DataFrames\n",
        "    if data_frames:\n",
        "        concatenated_df = pd.concat(data_frames, ignore_index=True)\n",
        "        return concatenated_df\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Path to the directory containing JSON files\n",
        "directory_path = \"/content/\"\n",
        "\n",
        "# Get all JSON files in the directory\n",
        "json_files = list_all_json_files(directory_path)\n",
        "print(f\"Ditemukan {len(json_files)} file JSON.\")\n",
        "\n",
        "# Read and concatenate all JSON files\n",
        "combined_df = read_and_concatenate_json_files(json_files)\n",
        "\n",
        "# Path to the output CSV file\n",
        "output_csv_file = os.path.join(directory_path, \"combined_data.csv\")\n",
        "\n",
        "# Save the combined DataFrame to a CSV file\n",
        "combined_df.to_csv(output_csv_file, index=False)\n",
        "print(f\"Data gabungan berhasil disimpan di {output_csv_file}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWnY5V_57M1R",
        "outputId": "3e0f751e-9f60-4844-f748-093778f34611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ditemukan 3055 file JSON.\n",
            "Gagal membaca /content/oct2022/2022-10-17/labels_2022_10_17_07_40_32.json: Expecting value: line 12 column 5 (char 165)\n",
            "Data gabungan berhasil disimpan di /content/combined_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path ke file CSV yang ingin dibaca\n",
        "csv_file_path = \"/content/combined_data.csv\"\n",
        "\n",
        "# Membaca file CSV ke dalam DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Menampilkan beberapa baris pertama dari DataFrame\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS3UuAG48dR7",
        "outputId": "358b69c3-6ced-40dd-d818-ee33a81b95f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   last_update_check_time  last_update_check_revision notifications  \\\n",
            "0            1.716903e+09                2.024052e+13            []   \n",
            "1                     NaN                         NaN           NaN   \n",
            "2                     NaN                         NaN           NaN   \n",
            "3                     NaN                         NaN           NaN   \n",
            "4                     NaN                         NaN           NaN   \n",
            "\n",
            "        brand brandtext category       type size     colors  season  ...  \\\n",
            "0         NaN       NaN      NaN        NaN  NaN        NaN     NaN  ...   \n",
            "1   Filippa K       NaN   Ladies    T-shirt   XL  ['Black']     All  ...   \n",
            "2        Only       NaN   Ladies        Top   38   ['Pink']     All  ...   \n",
            "3  Soul River       NaN   Ladies  Tank top    M    ['Pink']  Summer  ...   \n",
            "4      Lindex       NaN   Ladies        Top   M    ['Pink']     All  ...   \n",
            "\n",
            "   stains  holes          damage                              material  \\\n",
            "0     NaN    NaN             NaN                                   NaN   \n",
            "1     NaN    NaN             NaN                           100% cotton   \n",
            "2   Major    NaN  Pulled threads            97% polyester, 3% elastane   \n",
            "3   Major    NaN             NaN                        100% polyester   \n",
            "4     NaN    NaN             NaN  77% modal, 20%polyester, 3% elastane   \n",
            "\n",
            "                    comment    usage weight Series   X   Y  \n",
            "0                       NaN      NaN    NaN    NaN NaN NaN  \n",
            "1                   test 71    Reuse    NaN    NaN NaN NaN  \n",
            "2                   test 88   Export    NaN    NaN NaN NaN  \n",
            "3  test 69, detergent smell  Recycle    NaN    NaN NaN NaN  \n",
            "4                   test 85   Export    NaN    NaN NaN NaN  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    }
  ]
}